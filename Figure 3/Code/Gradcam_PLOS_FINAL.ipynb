{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to retrieve images by indices\n",
    "def get_images_by_indices(loader, indices, max_per_class=10):\n",
    "    wt_images = []\n",
    "    tpm_images = []\n",
    "    wt_labels = []\n",
    "    tpm_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, lbls) in enumerate(loader):\n",
    "            start_idx = i * loader.batch_size\n",
    "            for j in range(inputs.size(0)):\n",
    "                if start_idx + j in indices:\n",
    "                    if lbls[j].item() == 0 and len(wt_images) < max_per_class:  # WT\n",
    "                        wt_images.append(inputs[j])\n",
    "                        wt_labels.append('WT')\n",
    "                    elif lbls[j].item() == 1 and len(tpm_images) < max_per_class:  # TPM\n",
    "                        tpm_images.append(inputs[j])\n",
    "                        tpm_labels.append('TPM')\n",
    "                    if len(wt_images) >= max_per_class and len(tpm_images) >= max_per_class:\n",
    "                        break\n",
    "            if len(wt_images) >= max_per_class and len(tpm_images) >= max_per_class:\n",
    "                break\n",
    "    return wt_images, tpm_images, wt_labels, tpm_labels\n",
    "\n",
    "# Function to display and save images\n",
    "def show_and_save_images(images, labels, cols=5, title=\"\", filename=\"\"):\n",
    "    rows = len(images) // cols + 1\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    for i, img in enumerate(images):\n",
    "        ax = axs[i // cols, i % cols]\n",
    "        img = img.permute(1, 2, 0).cpu().numpy()\n",
    "        img = img - img.min()  # Normalize image to range [0, 1]\n",
    "        img = img / img.max()\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(labels[i])\n",
    "        ax.axis('off')\n",
    "    for j in range(i + 1, rows * cols):\n",
    "        axs[j // cols, j % cols].axis('off')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    if filename:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Function to display and save Grad-CAM images\n",
    "def show_and_save_gradcam_images(images, gradcams, labels, cols=5, title=\"\", filename=\"\"):\n",
    "    rows = len(images) // cols + 1\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    for i, (img, cam) in enumerate(zip(images, gradcams)):\n",
    "        ax = axs[i // cols, i % cols]\n",
    "        img = img.permute(1, 2, 0).cpu().numpy()\n",
    "        img = img - img.min()  # Normalize image to range [0, 1]\n",
    "        img = img / img.max()\n",
    "        ax.imshow(img)\n",
    "        ax.imshow(cam, cmap='jet', alpha=0.5)  # Overlay Grad-CAM\n",
    "        ax.set_title(labels[i])\n",
    "        ax.axis('off')\n",
    "    for j in range(i + 1, rows * cols):\n",
    "        axs[j // cols, j % cols].axis('off')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    if filename:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Load the dataset\n",
    "data_dir = '\\\\path\\\\to\\\\you'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Load the PHATE transformed features and labels, you must convert the csv used before to npy\n",
    "phate_transformed = np.load('phate_transformed_3d.npy')\n",
    "labels = np.load('labels_pool4.npy')\n",
    "\n",
    "# Define the transition zone coordinates (example values, adjust accordingly)\n",
    "transition_zone = ((phate_transformed[:, 0] > -0.02) & (phate_transformed[:, 0] < 0.02) &\n",
    "                   (phate_transformed[:, 1] > -0.02) & (phate_transformed[:, 1] < 0.02) &\n",
    "                   (phate_transformed[:, 2] > 0.0) & (phate_transformed[:, 2] < 0.06))\n",
    "\n",
    "# Define the most dense cluster coordinates (example values, adjust accordingly)\n",
    "dense_cluster = ((phate_transformed[:, 0] > -0.02) & (phate_transformed[:, 0] < 0.02) &\n",
    "                 (phate_transformed[:, 1] > -0.02) & (phate_transformed[:, 1] < 0.02) &\n",
    "                 (phate_transformed[:, 2] > -0.02) & (phate_transformed[:, 2] < 0.02))\n",
    "\n",
    "# Get indices of points in the transition zone and dense cluster\n",
    "transition_indices = np.where(transition_zone)[0]\n",
    "dense_indices = np.where(dense_cluster)[0]\n",
    "\n",
    "# Get images from the dense cluster and transition zone\n",
    "wt_dense_images, tpm_dense_images, wt_dense_labels, tpm_dense_labels = get_images_by_indices(loader, dense_indices)\n",
    "wt_trans_images, tpm_trans_images, wt_trans_labels, tpm_trans_labels = get_images_by_indices(loader, transition_indices)\n",
    "\n",
    "# Combine images and labels for dense cluster and transition zone\n",
    "dense_images = wt_dense_images + tpm_dense_images\n",
    "dense_labels = wt_dense_labels + tpm_dense_labels\n",
    "trans_images = wt_trans_images + tpm_trans_images\n",
    "trans_labels = wt_trans_labels + tpm_trans_labels\n",
    "\n",
    "# Display and save images from the dense cluster and transition zone\n",
    "show_and_save_images(dense_images, dense_labels, cols=5, title=\"Dense Cluster Images\", filename=\"dense_cluster_images.png\")\n",
    "show_and_save_images(trans_images, trans_labels, cols=5, title=\"Transition Zone Images\", filename=\"transition_zone_images.png\")\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(torch.load('resnet50_tpm_wt.pth', map_location=device))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Grad-CAM\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.forward_hook = target_layer.register_forward_hook(self.save_forward)\n",
    "        self.backward_hook = target_layer.register_full_backward_hook(self.save_backward)\n",
    "\n",
    "    def save_forward(self, module, input, output):\n",
    "        self.features = output\n",
    "\n",
    "    def save_backward(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(x)\n",
    "        score = output[:, output.max(1)[-1]].squeeze()\n",
    "        score.backward(retain_graph=True)\n",
    "        return self.features, self.gradients\n",
    "\n",
    "def apply_gradcam(model, images, target_layer, device):\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    cam_results = []\n",
    "    for img in images:\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        features, gradients = gradcam(img)\n",
    "        weights = F.adaptive_avg_pool2d(gradients, 1)\n",
    "        cam = torch.sum(weights * features, dim=1).squeeze().cpu().data.numpy()\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cam / cam.max()  # Normalize\n",
    "        cam_results.append(cam)\n",
    "    return cam_results\n",
    "\n",
    "# Apply Grad-CAM to dense cluster and transition zone images\n",
    "dense_gradcams = apply_gradcam(model, dense_images, model.layer4[2].conv3, device)\n",
    "trans_gradcams = apply_gradcam(model, trans_images, model.layer4[2].conv3, device)\n",
    "\n",
    "# Display and save Grad-CAM images from the dense cluster and transition zone\n",
    "show_and_save_gradcam_images(dense_images, dense_gradcams, dense_labels, cols=5, title=\"Dense Cluster Grad-CAM\", filename=\"dense_cluster_gradcam.png\")\n",
    "show_and_save_gradcam_images(trans_images, trans_gradcams, trans_labels, cols=5, title=\"Transition Zone Grad-CAM\", filename=\"transition_zone_gradcam.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
